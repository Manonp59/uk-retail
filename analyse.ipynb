{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse et nettoyage du jeu de données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement du fichier excel et transformation de chaque feuille en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chemin vers le fichier Excel d'entrée\n",
    "# excel_file_path = 'online_retail_II.xlsx'\n",
    "\n",
    "# # Charger le fichier Excel en utilisant pandas\n",
    "# xls = pd.ExcelFile(excel_file_path)\n",
    "\n",
    "# # Parcourir chaque feuille de calcul du fichier Excel\n",
    "# for sheet_name in xls.sheet_names:\n",
    "#     # Charger la feuille de calcul en tant que dataframe\n",
    "#     data_frame = xls.parse(sheet_name)\n",
    "    \n",
    "#     # Chemin vers le fichier CSV de sortie\n",
    "#     csv_file_path = f'online_retail{sheet_name}.csv'\n",
    "    \n",
    "#     # Convertir le dataframe en fichier CSV\n",
    "#     data_frame.to_csv(csv_file_path, index=False, encoding='utf-8')\n",
    "    \n",
    "# print('Conversion terminée.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concaténation des deux feuilles en un fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Chemin vers le premier fichier CSV\n",
    "# csv_file1 = 'online_retailYear 2009-2010.csv'\n",
    "\n",
    "# # Chemin vers le deuxième fichier CSV\n",
    "# csv_file2 = 'online_retailYear 2010-2011.csv'\n",
    "\n",
    "# # Charger les deux fichiers CSV en utilisant pandas\n",
    "# data_frame1 = pd.read_csv(csv_file1)\n",
    "# data_frame2 = pd.read_csv(csv_file2)\n",
    "\n",
    "# # Concaténer les deux dataframes\n",
    "# concatenated_data = pd.concat([data_frame1, data_frame2])\n",
    "\n",
    "# # Chemin vers le fichier CSV de sortie\n",
    "# output_csv = 'online_retail.csv'\n",
    "\n",
    "# # Enregistrer le dataframe concaténé en tant que fichier CSV\n",
    "# concatenated_data.to_csv(output_csv, index=False)\n",
    "\n",
    "# print('Concaténation terminée.')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ukretail = pd.read_csv('online_retail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier CSV dans un DataFrame\n",
    "df_ukretail = pd.read_csv('online_retail.csv')\n",
    "\n",
    "# Convertir la colonne 'InvoiceDate' en type datetime\n",
    "df_ukretail['InvoiceDate'] = pd.to_datetime(df_ukretail['InvoiceDate'])\n",
    "\n",
    "# Filtrer les données pour la période de 2009-2010\n",
    "df_2009_12_2010 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-12-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2010-12-31'))]\n",
    "\n",
    "# Générer les nouveaux DataFrames en ajoutant un mois à chaque fois\n",
    "df_2009_01_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-01-31'))]\n",
    "df_2009_02_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-02-28'))]\n",
    "df_2009_03_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-03-31'))]\n",
    "df_2009_04_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-04-30'))]\n",
    "df_2009_05_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-05-31'))]\n",
    "df_2009_06_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-06-30'))]\n",
    "df_2009_07_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-07-31'))]\n",
    "df_2009_08_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-08-31'))]\n",
    "df_2009_09_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-09-30'))]\n",
    "df_2009_10_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-10-31'))]\n",
    "df_2009_11_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-11-30'))]\n",
    "df_2009_12_2011 = df_ukretail[(df_ukretail['InvoiceDate'] >= pd.to_datetime('2009-01-01')) & (df_ukretail['InvoiceDate'] <= pd.to_datetime('2011-12-31'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2009_12_2010_copy = df_2009_12_2010.copy()\n",
    "df_2009_01_2011_copy = df_2009_01_2011.copy()\n",
    "df_2009_02_2011_copy = df_2009_02_2011.copy()\n",
    "df_2009_03_2011_copy = df_2009_03_2011.copy()\n",
    "df_2009_04_2011_copy = df_2009_04_2011.copy()\n",
    "df_2009_05_2011_copy = df_2009_05_2011.copy()\n",
    "df_2009_06_2011_copy = df_2009_06_2011.copy()\n",
    "df_2009_07_2011_copy = df_2009_07_2011.copy()\n",
    "df_2009_08_2011_copy = df_2009_08_2011.copy()\n",
    "df_2009_09_2011_copy = df_2009_09_2011.copy()\n",
    "df_2009_10_2011_copy = df_2009_10_2011.copy()\n",
    "df_2009_11_2011_copy = df_2009_11_2011.copy()\n",
    "df_2009_12_2011_copy = df_2009_12_2011.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_monthly_data_copy(df):\n",
    "    # Supprimer les lignes où le client n'est pas identifié\n",
    "    df = df.dropna(subset=['Customer ID'])\n",
    "\n",
    "    # Convertir la colonne 'Customer ID' en type str\n",
    "    df['Customer ID'] = df['Customer ID'].astype('str')\n",
    "\n",
    "    # Supprimer les lignes avec un prix <= 0\n",
    "    df = df[df['Price'] > 0]\n",
    "\n",
    "    # Supprimer les lignes où le stockcode est composé uniquement de lettres\n",
    "    df = df[~df['StockCode'].str.match(r'^[A-Za-z]')]\n",
    "\n",
    "    df = df[df['Quantity']>0]\n",
    "    \n",
    "    # Ajouter une colonne 'total' qui représente le prix unitaire multiplié par la quantité\n",
    "    df['total'] = df['Quantity'] * df['Price']\n",
    "\n",
    "    # Group by 'Customer ID' et 'Invoice' et calculer les sommes\n",
    "    df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
    "\n",
    "    # Group by 'Customer ID' et calculer les agrégats\n",
    "    df_rfm = df.groupby('Customer ID').agg({\n",
    "        'Invoice': 'nunique',\n",
    "        'Quantity': 'sum',\n",
    "        'InvoiceDate': 'max',\n",
    "        'total': 'sum'\n",
    "    })\n",
    "\n",
    "    # Renommer les colonnes du DataFrame df_rfm\n",
    "    df_rfm.columns = ['nombre_commandes', 'nombre_articles', 'date_derniere_commande', 'montant_total']\n",
    "    df_rfm = df_rfm[['montant_total','nombre_articles']]\n",
    "    df_rfm2 = df_rfm\n",
    "\n",
    "    return df_rfm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_monthly_data(df, df_rfm2):\n",
    "    # Supprimer les lignes où le client n'est pas identifié\n",
    "    df = df.dropna(subset=['Customer ID'])\n",
    "\n",
    "    # Convertir la colonne 'Customer ID' en type str\n",
    "    df['Customer ID'] = df['Customer ID'].astype('str')\n",
    "\n",
    "    # Supprimer les lignes avec un prix <= 0\n",
    "    df = df[df['Price'] > 0]\n",
    "\n",
    "    # Supprimer les lignes où le stockcode est composé uniquement de lettres\n",
    "    df = df[~df['StockCode'].str.match(r'^[A-Za-z]')]\n",
    "\n",
    "    # Ajouter une colonne 'total' qui représente le prix unitaire multiplié par la quantité\n",
    "    df['total'] = df['Quantity'] * df['Price']\n",
    "\n",
    "    # Group by 'Customer ID' et 'Invoice' et calculer les sommes\n",
    "    df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
    "\n",
    "    # Group by 'Customer ID' et calculer les agrégats\n",
    "    df_rfm = df.groupby('Customer ID').agg({\n",
    "        'Invoice': 'nunique',\n",
    "        'Quantity': 'sum',\n",
    "        'InvoiceDate': 'max',\n",
    "        'total': 'sum'\n",
    "    })\n",
    "\n",
    "    # Renommer les colonnes du DataFrame df_rfm\n",
    "    df_rfm.columns = ['nombre_commandes', 'nombre_articles', 'date_derniere_commande', 'montant_total']\n",
    "\n",
    "    # Compter le nombre de commandes annulées par client\n",
    "    cancelled_orders_count = df[df['Invoice'].str.startswith('C')].groupby('Customer ID')['Invoice'].nunique()\n",
    "\n",
    "    # Fusionner avec le DataFrame df_rfm\n",
    "    df_rfm = df_rfm.merge(cancelled_orders_count, how='left', on='Customer ID')\n",
    "    df_rfm['Invoice'] = df_rfm['Invoice'].fillna(0)\n",
    "\n",
    "    # Soustraire le nombre de commandes annulées du nombre total de commandes\n",
    "    df_rfm['nombre_commandes'] = df_rfm['nombre_commandes'] - df_rfm['Invoice']\n",
    "    df_rfm = df_rfm.rename(columns={'Invoice': 'transactions_annulation'})\n",
    "\n",
    "    # Calculer la valeur de 'Recency' en utilisant une date de référence fixe\n",
    "    date_max = str(df_rfm['date_derniere_commande'].max())\n",
    "    date_format = '%Y-%m-%d %H:%M:%S'\n",
    "    date_obj = datetime.strptime(date_max, date_format)\n",
    "    df_rfm['date_derniere_commande'] = pd.to_datetime(df_rfm['date_derniere_commande'])\n",
    "    df_rfm['nombre_jours_depuis_derniere_commande'] = (date_obj - df_rfm['date_derniere_commande']).dt.days\n",
    "\n",
    "    # Charger le DataFrame df_rfm2\n",
    "    df_rfm2 = pd.read_csv('df_rfm2.csv')\n",
    "    df_rfm2['Customer ID'] = df_rfm2['Customer ID'].astype('str')\n",
    "    \n",
    "    df_rfm2.columns = ['Customer ID', 'montant_total','nombre_articles']\n",
    "\n",
    "    # Fusionner avec le DataFrame df_rfm\n",
    "    df_rfm = df_rfm.merge(df_rfm2, how='left', on='Customer ID')\n",
    "    df_rfm = df_rfm.drop('nombre_articles_x', axis=1)\n",
    "\n",
    "    # Calculer le pourcentage d'annulation de montant\n",
    "    df_rfm['pourcentage_annulation_montant'] = ((df_rfm['montant_total_y'] - df_rfm['montant_total_x']) / df_rfm['montant_total_y']) * 100\n",
    "\n",
    "    # Supprimer les lignes avec un montant total négatif\n",
    "    df_rfm = df_rfm[df_rfm['montant_total_x'] >= 0]\n",
    "\n",
    "    # Calculer le nombre moyen d'articles par commande\n",
    "    df_rfm['nombre_articles_moyen_par_commande'] = df_rfm['nombre_articles_y'] / df_rfm['nombre_commandes']\n",
    "\n",
    "    # Calculer le panier moyen par client\n",
    "    df_rfm['panier_moyen'] = df_rfm['montant_total_y'] / df_rfm['nombre_commandes']\n",
    "\n",
    "    # Charger le DataFrame df_country\n",
    "    df_country = df[['Customer ID', 'Country']].drop_duplicates()\n",
    "\n",
    "    # Fusionner avec le DataFrame df_rfm\n",
    "    df_rfm = df_rfm.merge(df_country, how='left', on='Customer ID')\n",
    "    df_rfm =df_rfm.drop_duplicates(subset='Customer ID')\n",
    "    \n",
    "    # Renommer les colonnes \n",
    "    df_rfm = df_rfm.rename(columns = {'NombreArticles_y':'nombre_articles_total','Customer ID':'numero_client','montant_total_x':'montant_effectif','montant_total_y':'montant_global','Country':'pays'})\n",
    "\n",
    "    return df_rfm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/304799826.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/304799826.py:20: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n",
      "/tmp/ipykernel_64280/1801774541.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Customer ID'] = df['Customer ID'].astype('str')\n",
      "/tmp/ipykernel_64280/1801774541.py:21: FutureWarning: The default value of numeric_only in DataFrameGroupBy.sum is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  df_gp_invoice = df.groupby(['Customer ID', 'Invoice']).sum().drop('Price', axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_list = [\n",
    "    df_2009_12_2010,\n",
    "    df_2009_01_2011,\n",
    "    df_2009_02_2011,\n",
    "    df_2009_03_2011,\n",
    "    df_2009_04_2011,\n",
    "    df_2009_05_2011,\n",
    "    df_2009_06_2011,\n",
    "    df_2009_07_2011,\n",
    "    df_2009_08_2011,\n",
    "    df_2009_09_2011,\n",
    "    df_2009_10_2011,\n",
    "    df_2009_11_2011,\n",
    "    df_2009_12_2011\n",
    "]\n",
    "\n",
    "df_list_copy = [\n",
    "    df_2009_12_2011_copy,\n",
    "    df_2009_01_2011_copy,\n",
    "    df_2009_02_2011_copy,\n",
    "    df_2009_03_2011_copy,\n",
    "    df_2009_04_2011_copy,\n",
    "    df_2009_05_2011_copy,\n",
    "    df_2009_06_2011_copy,\n",
    "    df_2009_07_2011_copy,\n",
    "    df_2009_08_2011_copy,\n",
    "    df_2009_09_2011_copy,\n",
    "    df_2009_10_2011_copy,\n",
    "    df_2009_11_2011_copy,\n",
    "    df_2009_12_2011_copy\n",
    "]\n",
    "\n",
    "for i in range(len(df_list)):\n",
    "    df_list_copy[i] = clean_monthly_data_copy(df_list_copy[i])\n",
    "    df_list[i] = clean_monthly_data(df_list[i], df_list_copy[i])\n",
    "\n",
    "df_2009_12_2010 = df_list[0]\n",
    "df_2009_01_2011 = df_list[1]\n",
    "df_2009_02_2011 = df_list[2]\n",
    "df_2009_03_2011 = df_list[3]\n",
    "df_2009_04_2011 = df_list[4]\n",
    "df_2009_05_2011 = df_list[5]\n",
    "df_2009_06_2011 = df_list[6]\n",
    "df_2009_07_2011 = df_list[7]\n",
    "df_2009_08_2011 = df_list[8]\n",
    "df_2009_09_2011 = df_list[9]\n",
    "df_2009_10_2011 = df_list[10]\n",
    "df_2009_11_2011 = df_list[11]\n",
    "df_2009_12_2011 = df_list[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_outlier(column, lower_multiplier=1.5, upper_multiplier=1.5):\n",
    "    q1 = column.quantile(0.05)\n",
    "    q3 = column.quantile(0.95)\n",
    "    iqr = q3 - q1\n",
    "    lower_threshold = q1 - lower_multiplier * iqr\n",
    "    upper_threshold = q3 + upper_multiplier * iqr\n",
    "    outliers = (column < lower_threshold) | (column > upper_threshold)\n",
    "    return outliers\n",
    "\n",
    "\n",
    "def remove_outliers(df, lower_multiplier=1.5, upper_multiplier=1.5):\n",
    "    df_no_outliers = df.copy()\n",
    "    for column in df.select_dtypes(include=[np.number]).columns:\n",
    "        outliers = iqr_outlier(df[column], lower_multiplier, upper_multiplier)\n",
    "        df_no_outliers = df_no_outliers[~outliers]\n",
    "    return df_no_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n",
      "/tmp/ipykernel_64280/33839429.py:15: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df_no_outliers = df_no_outliers[~outliers]\n"
     ]
    }
   ],
   "source": [
    "df_no_outliers_2009_12_2010 = remove_outliers(df_2009_12_2010)\n",
    "df_no_outliers_2009_01_2011 = remove_outliers(df_2009_01_2011)\n",
    "df_no_outliers_2009_02_2011 = remove_outliers(df_2009_02_2011)\n",
    "df_no_outliers_2009_03_2011 = remove_outliers(df_2009_03_2011)\n",
    "df_no_outliers_2009_04_2011 = remove_outliers(df_2009_04_2011)\n",
    "df_no_outliers_2009_05_2011 = remove_outliers(df_2009_05_2011)\n",
    "df_no_outliers_2009_06_2011 = remove_outliers(df_2009_06_2011)\n",
    "df_no_outliers_2009_07_2011 = remove_outliers(df_2009_07_2011)\n",
    "df_no_outliers_2009_08_2011 = remove_outliers(df_2009_08_2011)\n",
    "df_no_outliers_2009_09_2011 = remove_outliers(df_2009_09_2011)\n",
    "df_no_outliers_2009_10_2011 = remove_outliers(df_2009_10_2011)\n",
    "df_no_outliers_2009_11_2011 = remove_outliers(df_2009_11_2011)\n",
    "df_no_outliers_2009_12_2011 = remove_outliers(df_2009_12_2011)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers_2009_12_2010.to_csv('df_no_outliers_2009_12_2010.csv', index=False)\n",
    "df_no_outliers_2009_01_2011.to_csv('df_no_outliers_2009_01_2011.csv', index=False)\n",
    "df_no_outliers_2009_02_2011.to_csv('df_no_outliers_2009_02_2011.csv', index=False)\n",
    "df_no_outliers_2009_03_2011.to_csv('df_no_outliers_2009_03_2011.csv', index=False)\n",
    "df_no_outliers_2009_04_2011.to_csv('df_no_outliers_2009_04_2011.csv', index=False)\n",
    "df_no_outliers_2009_05_2011.to_csv('df_no_outliers_2009_05_2011.csv', index=False)\n",
    "df_no_outliers_2009_06_2011.to_csv('df_no_outliers_2009_06_2011.csv', index=False)\n",
    "df_no_outliers_2009_07_2011.to_csv('df_no_outliers_2009_07_2011.csv', index=False)\n",
    "df_no_outliers_2009_08_2011.to_csv('df_no_outliers_2009_08_2011.csv', index=False)\n",
    "df_no_outliers_2009_09_2011.to_csv('df_no_outliers_2009_09_2011.csv', index=False)\n",
    "df_no_outliers_2009_10_2011.to_csv('df_no_outliers_2009_10_2011.csv', index=False)\n",
    "df_no_outliers_2009_11_2011.to_csv('df_no_outliers_2009_11_2011.csv', index=False)\n",
    "df_no_outliers_2009_12_2011.to_csv('df_no_outliers_2009_12_2011.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numero_client</th>\n",
       "      <th>nombre_commandes</th>\n",
       "      <th>date_derniere_commande</th>\n",
       "      <th>montant_effectif</th>\n",
       "      <th>transactions_annulation</th>\n",
       "      <th>nombre_jours_depuis_derniere_commande</th>\n",
       "      <th>montant_global</th>\n",
       "      <th>nombre_articles_y</th>\n",
       "      <th>pourcentage_annulation_montant</th>\n",
       "      <th>nombre_articles_moyen_par_commande</th>\n",
       "      <th>panier_moyen</th>\n",
       "      <th>pays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12347.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2011-12-07 15:52:00</td>\n",
       "      <td>5633.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5633.32</td>\n",
       "      <td>3286.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>410.750000</td>\n",
       "      <td>704.165</td>\n",
       "      <td>Iceland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12348.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011-09-25 13:13:00</td>\n",
       "      <td>1658.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74</td>\n",
       "      <td>1658.40</td>\n",
       "      <td>2704.0</td>\n",
       "      <td>1.371042e-14</td>\n",
       "      <td>540.800000</td>\n",
       "      <td>331.680</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12349.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2011-11-21 09:51:00</td>\n",
       "      <td>3654.54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>3678.69</td>\n",
       "      <td>1621.0</td>\n",
       "      <td>6.564837e-01</td>\n",
       "      <td>540.333333</td>\n",
       "      <td>1226.230</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12350.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-02 16:01:00</td>\n",
       "      <td>294.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>309</td>\n",
       "      <td>294.40</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>294.400</td>\n",
       "      <td>Norway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12351.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-11-29 15:23:00</td>\n",
       "      <td>300.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>374</td>\n",
       "      <td>300.93</td>\n",
       "      <td>261.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>300.930</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  numero_client  nombre_commandes date_derniere_commande  montant_effectif  \\\n",
       "1       12347.0               8.0    2011-12-07 15:52:00           5633.32   \n",
       "2       12348.0               5.0    2011-09-25 13:13:00           1658.40   \n",
       "3       12349.0               3.0    2011-11-21 09:51:00           3654.54   \n",
       "4       12350.0               1.0    2011-02-02 16:01:00            294.40   \n",
       "5       12351.0               1.0    2010-11-29 15:23:00            300.93   \n",
       "\n",
       "   transactions_annulation  nombre_jours_depuis_derniere_commande  \\\n",
       "1                      0.0                                      1   \n",
       "2                      0.0                                     74   \n",
       "3                      1.0                                     18   \n",
       "4                      0.0                                    309   \n",
       "5                      0.0                                    374   \n",
       "\n",
       "   montant_global  nombre_articles_y  pourcentage_annulation_montant  \\\n",
       "1         5633.32             3286.0                    0.000000e+00   \n",
       "2         1658.40             2704.0                    1.371042e-14   \n",
       "3         3678.69             1621.0                    6.564837e-01   \n",
       "4          294.40              196.0                    0.000000e+00   \n",
       "5          300.93              261.0                    0.000000e+00   \n",
       "\n",
       "   nombre_articles_moyen_par_commande  panier_moyen         pays  \n",
       "1                          410.750000       704.165      Iceland  \n",
       "2                          540.800000       331.680      Finland  \n",
       "3                          540.333333      1226.230        Italy  \n",
       "4                          196.000000       294.400       Norway  \n",
       "5                          261.000000       300.930  Unspecified  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_outliers_2009_12_2011.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'NombreArticlesMoyenParCommande'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[164], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m plt\u001b[39m.\u001b[39mhist(df_no_outliers_2009_12_2010\u001b[39m.\u001b[39;49mNombreArticlesMoyenParCommande)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5895\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5896\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5897\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5898\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5899\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5900\u001b[0m ):\n\u001b[1;32m   5901\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5902\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'NombreArticlesMoyenParCommande'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_no_outliers_2009_12_2010.NombreArticlesMoyenParCommande)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28ff26c65758d064959116f1d9c8fbca26d00c18c6d798db5e6a86c21bd645e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
